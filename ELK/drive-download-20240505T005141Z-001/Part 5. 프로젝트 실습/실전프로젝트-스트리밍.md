

## 실전 프로젝트

- 지난 강의들을 종합해보는 프로젝트
- 가상 시나리오를 설정하고 배운 내용들을 통해 문제를 해결해보자



## 스트리밍 시나리오

> 여러분은 **Fast Jake Company**의 **Data Enineer**입니다.
>
> 타 팀에서 요청이 들어왔습니다.
>
> "**비트코인의 가격**을 **실시간**으로 볼 수 있는 **대시보드**를 제공해주실 수 있나요? 업무에 사용해야 하는데... 꼭 필요해서요!"
>
> 여러분에게 주어진 과제는 **API로부터 데이터를 받아 스트리밍으로 시각화 해달라는 요건을 해결하는 것입니다.**

- 요청을 자세히 들어보니 비트코인에 대한 외부 데이터 소스에서 데이터를 연동해서 실시간으로 대시보드를 제공하는 것입니다.
- 배운 내용을 복기하면서 어떻게 연동을 할지 대시보드를 만들 수 있는지 생각해 봅시다.





## 스트리밍 파이프라인 설계

![api-pipeline](image/api-pipeline.png)

- 코인의 가격을 실시간으로 봐야하기 때문에 이것을 볼 수 있는 데이터 소스를 확인해야 합니다.
- 업비트에서는 코인의 정보에 대해서 API로 제공을 하고 있습니다.
- API에 있는 데이터를 받아 Kafka에 넣을 수 있는 Producer를 만들 수 있습니다.
- Kafka에서 데이터를 가져가는 Consumer를 만들 수 있습니다.
- 스트리밍으로 대시보드를 제공하기 위해 Elastic 스택을 활용할 수 있습니다.
- API -> Kafka -> Logstash -> Elsticsearch -> Kibana 으로 데이터 파이프라인을 구성하고 대시보드를 만들어 볼 수 있습니다.
  - 혹시 모를 상황에 대비해 Elasticsearch로 데이터를 전송할 때, S3에도 데이터를 저장해보겠습니다.



### 업비트 API

- 업비트 API 사용을 위해 업비트에 먼저 회원가입이 필요하다
- 로그인 후 `Open API 안내`로 이동
  - https://upbit.com/service_center/open_api_guide
  - Open API Key 발급받기 
  - **자산조회 , 주문조회** 만 선택 후 키 발급
  - 허용 IP주소 는 로컬PC IP로 우선 사용
- AccessKey, SecretKey를 저장
  - **보안 철저!!!**
  - **절대 유출되지 않도록 보관**

- Upbit API 사용해보기

  - ```python
    # pip install pyupbit
    
    import requests
    import pyupbit
    
    access = "{access_key}"          # 본인 값으로 변경
    secret = "{secret_key}"          # 본인 값으로 변경
    upbit = pyupbit.Upbit(access, secret)
    
    querystring = {"markets":"KRW-BTC"} #비트코인
    
    url = f"https://api.upbit.com/v1/ticker"
    
    headers = {"accept": "application/json"}
    
    response = requests.get(url, headers=headers, params=querystring)
    
    response.json()
    ```

  - API 문서 참고
    - https://docs.upbit.com/reference/ticker%ED%98%84%EC%9E%AC%EA%B0%80-%EC%A0%95%EB%B3%B4



### Kafka

- 서버 재시작

- 기존에 실행했던 내역들을 지워야 정상적으로 기동이 가능함

  - `cd /kafka/kafka_2.13-3.3.2/data/version-2`
  - version-2를 삭제
  - `/kafka/kafka_2.13-3.3.2/logs/meta.properties` 삭제

- 각 노드에서 카프카 재실행

  - ```shell
    $KAFKA_HOME/bin/zookeeper-server-start.sh -daemon $KAFKA_HOME/config/zookeeper.properties
    $KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties
    ```

- ui-for-kafka 재실행

  - `sudo docker-compose up kafka-ui`
  - `nohup sudo docker-compose up kafka-ui &`

- API 토픽 생성

- ```
  $KAFKA_HOME/bin/kafka-topics.sh --create --bootstrap-server kafka_node1:9092 --replication-factor 1 --partitions 3 --topic upbit-api
  ```

  

### Producer

- API에서 Kafka로 보내는 Producer를 서버에 올린다

- ```python
  #producer.py
  import json
  import requests
  from confluent_kafka import Producer
  import time
  
  import requests
  import pyupbit
  
  access = "{access_key}"          # 본인 값으로 변경
  secret = "{secret_key}"          # 본인 값으로 변경
  upbit = pyupbit.Upbit(access, secret)
  
  querystring = {"markets":"KRW-BTC"}
  
  headers = {"accept": "application/json"}
  
  
  def delivery_report(err, msg):
      """ Called once for each message produced to indicate delivery result.
          Triggered by poll() or flush(). """
      if err is not None:
          print('Message delivery failed: {}'.format(err))
      else:
          print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))
    
  
  producer = Producer({'bootstrap.servers': '172.31.0.225:9092'})
  
  while True:
      api_server='https://api.upbit.com/v1/ticker'
      response = requests.get(api_server, headers=headers, params=querystring)
      data = response.json()
      json_data = json.dumps(data[0])
      producer.poll(0)
      producer.produce("upbit-api", json_data, callback=delivery_report)
      producer.flush()
  ```

- `python3 producer.py` 로 카프카에 메세지를 보낸다



### Kafka to Elasticsearch

- kafka 토픽에서 Logstash를 통해 Elasticsearch로 전송
- 필요한 conf파일은 input-filter-output
  - filter는 생략
- upbit-api-input.conf

```
input {
  kafka {
    bootstrap_servers => "172.31.0.225:9092,172.31.6.46:9092,172.31.11.108:9092" #Kafka PrivateIP
    topics => "upbit-api"
    group_id => "upbit-api-01"
    client_id => "logstash-01-upbit-api"
    consumer_threads => 1
    auto_offset_reset => "earliest"
    codec => "json"
  }
}

filter {
  mutate {
    add_field => { "pipeline_id" => "upbit-api" }
    add_field => { "idx_name" => "upbit-api" }
    add_field => { "s3_bucket" => "jake-api" }
    add_field => { "s3_path" => "/api/upbit-api" }
  }
}

output {
  pipeline {
    send_to => ["upbit-api-output-es","upbit-api-output-s3"]
  }
}
```



output filter - 2

- 1. upbit-api.output-es.conf

```
input {
  pipeline {
    address => "upbit-api-output-es"
  }
}

filter {
}

output {
  elasticsearch {
    hosts => ["{ES Public IP}:9200"]
    index =>"%{idx_name}-%{+YYYY.ww}"
    user => "elastic"
    password => "qlalfqjsgh"
    manage_template => false
    document_type => "_doc"
  }
}
```

- 2. upbit-api.output-s3.conf

- ```
  input {
    pipeline {
      address => "upbit-api-output-s3"
    }
  }
  
  filter {
  }
  
  output {
    s3 {
      region => "ap-northeast-2"
      bucket => "jake-api"
      prefix => "%{s3_path}/year=%{+yyyy}/month=%{+MM}/day=%{+dd}/hour=%{+HH}/"
      size_file => 67108864 # bytes
      time_file => 1 # minutes
      rotation_strategy => "size_and_time"
      codec => "json_lines"
    }
  }
  ```

  - output plugin 설치
    - bin/logstash-plugin install logstash-output-s3
    - S3로 전송하기 위해 aws-cli설치
      - sudo apt  install awscli
      - aws configure
      - credential 설정
  
- `pipelines.yml`로 묶어주기

  - `bin/logstash` 를 사용하면 기본적으로 pipelines.yml 설정을 읽어 파이프라인을 생성

  - 이 파일에 사용할 conf들을 등록해주면 여러 output을 생성하더라도 쉽게 설정이 가능

  - ```
    - pipeline.id: upbit-api
      path.config: "/home/ubuntu/logstash-7.10.2/config/upbit-api.conf"
      pipeline.workers: 1
      queue.page_capacity: 64mb
      queue.type: persisted
    
    - pipeline.id: upbit-api-output-es
      path.config: "/home/ubuntu/logstash-7.10.2/config/upbit-api.output-es.conf"
      pipeline.workers: 1
      queue.page_capacity: 64mb
      queue.type: persisted
    
    - pipeline.id: upbit-api-output-s3
      path.config: "/home/ubuntu/logstash-7.10.2/config/upbit-api.output-s3.conf"
      pipeline.workers: 1
      queue.page_capacity: 64mb
      queue.type: persisted
    ```

  - 생성되는 파이프라인은 총 3개

    - `upbit-api`,` upbit-api-output-es`, `upbit-api-output-s3`

  * 만약 파이프라인이 정상적으로 실행되지 않거나 중간에 fail이 난다면,
    * offset을 처음으로 돌려놓고 재작업





### Kibana 대시보드

- api 정보 활용
- https://docs.upbit.com/reference/%EC%A0%84%EC%B2%B4-%EA%B3%84%EC%A2%8C-%EC%A1%B0%ED%9A%8C





